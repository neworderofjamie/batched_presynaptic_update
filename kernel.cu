// Standard C++ includes
#include <algorithm>
#include <chrono>
#include <iostream>
#include <numeric>
#include <random>
#include <stdexcept>
#include <string>
#include <sstream>
#include <vector>

// Standard C includes
#include <cassert>
#include <cmath>

// CUDA includes
#include <cooperative_groups.h>
#include <cuda_runtime.h>
#include <curand_kernel.h>
#include <device_launch_parameters.h>

//------------------------------------------------------------------------
// Macros
//------------------------------------------------------------------------
#define SEED 124

#define CHECK_CUDA_ERRORS(call) {                                                                   \
    cudaError_t error = call;                                                                       \
    if (error != cudaSuccess) {                                                                     \
            std::ostringstream errorMessageStream;                                                  \
            errorMessageStream << "cuda error:" __FILE__ << ": " << __LINE__ << " ";                \
            errorMessageStream << cudaGetErrorString(error) << "(" << error << ")" << std::endl;    \
            throw std::runtime_error(errorMessageStream.str());                                     \
        }                                                                                           \
    }

template<typename T>
using HostDeviceArray = std::pair < T*, T* > ;

enum Mode
{
    ModeSparsePost,
    ModeMax,
};


const char *const s_ModeNames[] = {
    "Sparse Post"};

//------------------------------------------------------------------------
// SparseMatrix
//------------------------------------------------------------------------
// Yale format sparse matrix
struct SparseMatrix
{
    unsigned int maxRowLength;
    HostDeviceArray<unsigned int> rowLength;
    HostDeviceArray<unsigned int> indices;
};

//------------------------------------------------------------------------
// Timer
//------------------------------------------------------------------------
template<typename A = std::milli>
class Timer
{
public:
    Timer(const std::string &title) : m_Start(std::chrono::high_resolution_clock::now()), m_Title(title)
    {
    }

    ~Timer()
    {
        std::cout << m_Title << get() << std::endl;
    }

    //------------------------------------------------------------------------
    // Public API
    //------------------------------------------------------------------------
    double get() const
    {
        auto now = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> duration = now - m_Start;
        return duration.count();
    }

private:
    //------------------------------------------------------------------------
    // Members
    //------------------------------------------------------------------------
    std::chrono::time_point<std::chrono::high_resolution_clock> m_Start;
    std::string m_Title;
};

//-----------------------------------------------------------------------------
// Device functions
//-----------------------------------------------------------------------------
//  Von Neumann'synBlk exponential distribution generator from Ripley p.230
//  Mean number of U(0,1) per call = 5.2
__device__ float exponentialDist(curandState &rng) {
    float a = 0.0f;

    while (true) {
        float u = curand_uniform(&rng);
        const float u0 = u;

        while (true) {
            float uStar = curand_uniform(&rng);
            if (u < uStar) {
                return  a + u0;
            }

            u = curand_uniform(&rng);

            if (u >= uStar) {
                break;
            }
        }

        a += 1.0f;
    }
}
//-----------------------------------------------------------------------------
// Kernel to initialise device RNG seed
template<typename RNGStateType>
__global__ void initRandomSeed(unsigned int sequenceStart, unsigned int numSeed, RNGStateType *d_rowState)
{
    const int i = threadIdx.x + (blockIdx.x * blockDim.x);
    if (i < numSeed) {
        curand_init(SEED, sequenceStart + i, 0, &d_rowState[i]);
    }

}
//-----------------------------------------------------------------------------
// Kernel to initialise initial Poisson time-to-spike
__global__ void initPoissonTimeToSpike(unsigned int numPoisson, const float *d_meanISI, curandState *d_poissonState,
                                       float *d_timeToSpike)
{
    // Get index of neuron in population
    const int i = threadIdx.x + (blockIdx.x * blockDim.x);
    if (i < numPoisson) {
        d_timeToSpike[i] = d_meanISI[i] * exponentialDist(d_poissonState[i]);
    }
}
//-----------------------------------------------------------------------------
// Kernel to simulate population of poisson neurons
__global__ void poisson(unsigned int numPoisson, const float *d_meanISI, curandState *d_poissonState,
                        float *d_timeToSpike, unsigned int *d_numOutSpikes, unsigned int *d_outSpikes)
{
    // Count and buffer to hold spikes output by this block
    __shared__ unsigned int blockSpikeCount;
    extern __shared__ unsigned int blockOutSpikes[];

    // Offset into global spike output buffer
    __shared__ unsigned int blockSpikeOffset;

    // Get index of neuron in population
    const int i = threadIdx.x + (blockIdx.x * blockDim.x);
    const unsigned int batch = blockIdx.y;

    // Use first thread in each block to zero spike counts
    if (threadIdx.x == 0) {
        blockSpikeCount = 0;
    }
    __syncthreads();

    // If there is a neuron for this thread to simulate
    const unsigned int batchOffset = numPoisson * batch;
    if (i < numPoisson) {
        float tts = d_timeToSpike[batchOffset + i];

        if (tts <= 0.0f) {
            tts += (d_meanISI[batchOffset + i] * exponentialDist(d_poissonState[batchOffset + i]));

            // Add spike to output
            unsigned int blockSpikeIndex = atomicAdd(&blockSpikeCount, 1);
            blockOutSpikes[blockSpikeIndex] = i;
        }

        d_timeToSpike[batchOffset + i] = (tts - 1.0f);
    }

    // If block has emitted any spikes, use the first thread to  
    // determine where in global spike output buffer to copy them
    __syncthreads();
    if (threadIdx.x == 0 && blockSpikeCount > 0) {
        blockSpikeOffset = atomicAdd(&d_numOutSpikes[batch], blockSpikeCount);
    }

    // Copy spikes from block output buffer into correct offset in global buffer
    __syncthreads();
    if (threadIdx.x < blockSpikeCount) {
        d_outSpikes[batchOffset + blockSpikeOffset + threadIdx.x] = blockOutSpikes[threadIdx.x];
    }
}
//-----------------------------------------------------------------------------
__global__ void sparsePostIndividualWeight(const unsigned int *d_rowLength, const unsigned int *d_indices, 
                                           unsigned int numPre, unsigned int numPost, unsigned int maxRowLength,
                                           const unsigned int *d_numInSpikes, const unsigned int *d_inSpikes,
                                           const float *d_weights, float *d_outCurrents)
{
    extern __shared__ unsigned int s_buffer[];
    unsigned int *s_spike = &s_buffer[0];
    unsigned int *s_rowLength = &s_buffer[blockDim.x];

    const unsigned int id = threadIdx.x + (blockIdx.x * blockDim.x);
    const unsigned int batch = blockIdx.y;

    // Calculate number of blocks (dictated by shared memory) spikes need to be processed in
    const unsigned int numSpikes = d_numInSpikes[batch];
    const unsigned int numSpikeBlocks = (numSpikes + blockDim.x - 1) / blockDim.x;
    const unsigned int preBatchOffset = numPre * batch;
    const unsigned int postBatchOffset = numPost * batch;

    // Loop through spikes blocks
    for (unsigned int b = 0; b < numSpikeBlocks; b++) {
        // Determine how many spikes are in this block
        const unsigned int numSpikesInBlock = (b == (numSpikeBlocks - 1))
            ? ((numSpikes - 1) % blockDim.x) + 1 : blockDim.x;

        __syncthreads();

       // Use first row of threads in block to read spikes and row lengths into shared memory
        if (threadIdx.x < numSpikesInBlock) {
            const unsigned int i = d_inSpikes[preBatchOffset + (b * blockDim.x) + threadIdx.x];
            s_spike[threadIdx.x] = i;
            s_rowLength[threadIdx.x] = d_rowLength[i];
        }

        __syncthreads();

        // If there is a synapse for this thread to process
        if(id < maxRowLength) {
            // Loop through spikes in block
            for(unsigned int i = 0; i < numSpikesInBlock; i++)
            {
                // If there is a synapse for this thread to process
                if(id < s_rowLength[i]) {
                    // Get postsynaptic index
                    const unsigned int synAddress = (s_spike[i] * maxRowLength) + id;
                    const unsigned int j = d_indices[synAddress];

                    // Add input current
                    atomicAdd(&d_outCurrents[postBatchOffset + j], d_weights[synAddress]);
                }
            }
        }

    }
}
//-----------------------------------------------------------------------------
__global__ void fixedProbabilitySkipConstant(float probabilityReciprocal, unsigned int numPre, unsigned int numPost, unsigned int numPostThreads,
                                             const curandState *d_rowState,
                                             const unsigned int *d_numInSpikes, const unsigned int *d_inSpikes,
                                             float *d_outCurrents)
{
    const unsigned int id = threadIdx.x + (blockIdx.x * blockDim.x);
    const unsigned int i = id / numPostThreads;
    const unsigned int j = id % numPostThreads;

    if (i < d_numInSpikes[0]) {
        // Copy row state corresponding to spike into register
        // **PROFILING** d_inSpikes[spkIdx] is nicely coalesced
        // **HOWEVER** d_rowState is not - if neurons fire at 10Hz on average only 1/100 will spike meaing this won't coalesce well
        curandState localState = d_rowState[(d_inSpikes[i] * numPostThreads) + j];

        const unsigned int numPostPerThread = (unsigned int)ceilf((float)numPost / (float)numPostThreads);

        // Loop through columns
        const unsigned int postStart = j * numPostPerThread;
        const unsigned int postEnd = min(postStart + numPostPerThread, numPost);


        // Loop through columns
        for (int j = postStart - 1;;)
        {
            // Draw from uniform
            const float u = curand_uniform(&localState);

            j += (1 + (int)(__logf(u) * probabilityReciprocal));
            if (j < postEnd) {
                // Add input current
                atomicAdd(&d_outCurrents[j], 1.0f);
            }
            else {
                break;
            }

        }
    }
}
//-----------------------------------------------------------------------------
__global__ void fixedProbabilitySkipUniform(float probabilityReciprocal, unsigned int numPre, unsigned int numPost, unsigned int numPostThreads,
                                            const curandState *d_rowState,
                                            const unsigned int *d_numInSpikes, const unsigned int *d_inSpikes,
                                            float *d_outCurrents)
{
    const unsigned int id = threadIdx.x + (blockIdx.x * blockDim.x);
    const unsigned int i = id / numPostThreads;
    const unsigned int j = id % numPostThreads;

    if (i < d_numInSpikes[0]) {
        // Copy row state corresponding to spike into register
        // **PROFILING** d_inSpikes[spkIdx] is nicely coalesced
        // **HOWEVER** d_rowState is not - if neurons fire at 10Hz on average only 1/100 will spike meaing this won't coalesce well
        curandState localState = d_rowState[(d_inSpikes[i] * numPostThreads) + j];

        const unsigned int numPostPerThread = (unsigned int)ceilf((float)numPost / (float)numPostThreads);

        // Loop through columns
        const unsigned int postStart = j * numPostPerThread;
        const unsigned int postEnd = min(postStart + numPostPerThread, numPost);


        // Loop through columns
        for (int j = postStart - 1;;)
        {
            // Draw from uniform
            const float u = curand_uniform(&localState);
            const float w = curand_uniform(&localState);

            j += (1 + (int)(__logf(u) * probabilityReciprocal));
            if (j < postEnd) {
                // Add input current
                atomicAdd(&d_outCurrents[j], (w * 0.7f) + 0.1f);
            }
            else {
                break;
            }

        }
    }
}

//-----------------------------------------------------------------------------
// Host functions
//-----------------------------------------------------------------------------
template<typename T>
HostDeviceArray<T> allocateHostDevice(unsigned int count)
{
    T *array = nullptr;
    T *d_array = nullptr;
    CHECK_CUDA_ERRORS(cudaMallocHost(&array, count * sizeof(T)));
    CHECK_CUDA_ERRORS(cudaMalloc(&d_array, count * sizeof(T)));

    return std::make_pair(array, d_array);
}
//-----------------------------------------------------------------------------
template<typename T>
void hostToDeviceCopy(HostDeviceArray<T> &array, unsigned int count, bool deleteHost=false)
{
    CHECK_CUDA_ERRORS(cudaMemcpy(array.second, array.first, sizeof(T) * count, cudaMemcpyHostToDevice));
    if (deleteHost) {
        CHECK_CUDA_ERRORS(cudaFreeHost(array.first));
        array.first = nullptr;
    }
}
//-----------------------------------------------------------------------------
template<typename T>
void deviceToHostCopy(HostDeviceArray<T> &array, unsigned int count)
{
    CHECK_CUDA_ERRORS(cudaMemcpy(array.first, array.second, count * sizeof(T), cudaMemcpyDeviceToHost));
}
//-----------------------------------------------------------------------------
// Evaluates continued fraction for incomplete beta function by modified Lentz'synBlk method
// Adopted from numerical recipes in C p227
double betacf(double a, double b, double x)
{
    const int maxIterations = 200;
    const double epsilon = 3.0E-7;
    const double fpMin = 1.0E-30;

    const double qab = a + b;
    const double qap = a + 1.0;
    const double  qam = a - 1.0;
    double c = 1.0;

    // First step of Lentz�s method.
    double d = 1.0 - qab * x / qap;
    if(fabs(d) < fpMin) {
        d = fpMin;
    }
    d = 1.0 / d;
    double h = d;
    int m;
    for(m = 1; m <= maxIterations; m++) {
        const double m2 = 2.0 * m;
        const double aa1 = m * (b - m) * x / ((qam + m2) * (a + m2));
        d = 1.0 + aa1 * d;

        // One step (the even one) of the recurrence.
        if(fabs(d) < fpMin) {
            d = fpMin;
        }
        c = 1.0 + aa1 / c;
        if(fabs(c) < fpMin) {
            c = fpMin;
        }
        d = 1.0 / d;
        h *= d * c;
        const double aa2 = -(a + m) * (qab + m) * x / ((a + m2) * (qap + m2));
        d = 1.0 + aa2 * d;

        // Next step of the recurrence (the odd one).
        if(fabs(d) < fpMin) {
            d = fpMin;
        }
        c = 1.0 + aa2 / c;
        if(fabs(c) < fpMin) {
            c = fpMin;
        }
        d = 1.0 / d;
        const double del = d * c;
        h *= del;

        // Are we done?
        if(fabs(del - 1.0) < epsilon) {
            break;
        }
    }
    if(m > maxIterations) {
        throw std::runtime_error("a or b too big, or MAXIT too small in betacf");
    }
    return h;
}
//----------------------------------------------------------------------------
// Returns the incomplete beta function Ix(a, spkBlk)
// Adopted from numerical recipes in C p227
double betai(double a, double b, double x)
{
    if(x < 0.0 || x > 1.0) {
        throw std::runtime_error("Bad x in routine betai");
    }

    // Factors in front of the continued fraction.
    double bt;
    if(x == 0.0 || x == 1.0) {
        bt = 0.0;
    }
    else {
        bt = exp(lgamma(a + b) - lgamma(a) - lgamma(b) + a * log(x) + b * log(1.0 - x));
    }

    // Use continued fraction directly.
    if(x < ((a + 1.0) / (a + b + 2.0))) {
        return bt * betacf(a, b, x) / a;
    }
    // Otherwise, use continued fraction after making the 
    // symmetry transformation.
    else {
        return 1.0 - (bt * betacf(b, a, 1.0 - x) / b);
    }
}
//----------------------------------------------------------------------------
// Evaluates inverse CDF of binomial distribution
unsigned int binomialInverseCDF(double cdf, unsigned int n, double p)
{
    if(cdf < 0.0 || 1.0 < cdf) {
        throw std::runtime_error("binomialInverseCDF error - CDF < 0 or 1 < CDF");
    }

    // Loop through ks <= n
    for(unsigned int k = 0; k <= n; k++) {
        // Use incomplete beta function to evalauate CDF, if it'synBlk greater than desired CDF value, return k
        if(betai(n - k, 1 + k, 1.0 - p) > cdf) {
            return k;
        }

    }

    throw std::runtime_error("Invalid CDF parameterse");
}
//-----------------------------------------------------------------------------
template <typename Generator>
void buildFixedProbabilityConnector(unsigned int numPre, unsigned int numPost, float probability,
                                    SparseMatrix &projection, Generator &gen)
{
    const double probabilityReciprocal = 1.0 / std::log(1.0f - probability);

    // Calculate suitable quantile for 0.9999 change when drawing numPre times
    const double quantile = pow(0.9999, 1.0 / (double)numPre);

    // Calculate max row length
    projection.maxRowLength = binomialInverseCDF(quantile, numPost, probability);

    // Allocate memory for row length and indices
    projection.rowLength = allocateHostDevice<unsigned int>(numPre);
    projection.indices = allocateHostDevice<unsigned int>(numPre * projection.maxRowLength);

    // Create RNG to draw probabilities
    std::uniform_real_distribution<> dis(0.0, 1.0);

    // Zero row lengths
    std::fill_n(projection.rowLength.first, numPre, 0);

    // Loop through potential synapses
    const int64_t maxConnections = (int64_t)numPre * (int64_t)numPost;
    for(int64_t s = -1;;) {
        // Skip to next connection
        s += (1 + (int64_t)(std::log(dis(gen)) * probabilityReciprocal));

        // If we haven't skipped past end of matrix
        if(s < maxConnections) {
            // Convert synapse number to pre and post index
            const auto prePost = std::div(s, numPost);

            // Get pointer to start of this presynaptic neuron'synBlk connection row
            unsigned int *rowIndices = &projection.indices.first[prePost.quot * projection.maxRowLength];

            // Add synapse
            rowIndices[projection.rowLength.first[prePost.quot]++] = prePost.rem;
            assert(projection.rowLength.first[prePost.quot] <= projection.maxRowLength);
        }
        else {
            break;
        }
    }

    // Upload connectivity
    hostToDeviceCopy(projection.rowLength, numPre, true);
    hostToDeviceCopy(projection.indices, numPre * projection.maxRowLength, true);
}
//-----------------------------------------------------------------------------
int main(int argc, char *argv[])
{
    try
    {
        unsigned int blockSize = 32;
        unsigned int numPre = 10000;
        unsigned int numPost = 10000;
        const float connectionProbability = 0.1f;
        unsigned int batchSize = 32;
        const float dt = 1.0f;
        const float poissonRate = 10.0f;
    
        // Read mode from command line
        Mode mode;
        if(argc < 2) {
            std::cerr << "Expected parameters specifying:" << std::endl;
            std::cerr << "\t Mode (";
            for(int m = 0; m < ModeMax; m++) {
                std::cerr << m << " = " << s_ModeNames[m];
                if(m != (ModeMax - 1)) {
                    std::cerr << ", ";
                }
            }
            std::cerr << ")" << std::endl;
            return EXIT_FAILURE;
        }
        else {
            mode = (Mode)std::stoul(argv[1]);
        }
    
        // If additional parameters are specified, read N
        if(argc > 2) {
            numPre = numPost = std::stoul(argv[2]);
        }
        // If additional parameters are specified, read number of postsynaptic blocks
        if(argc > 3) {
            batchSize = std::stoul(argv[3]);
        }
        if(argc > 4) {
            blockSize = std::stoul(argv[4]);
        }

        const unsigned int preBlocks = (unsigned int)std::ceil((float)numPre / (float)blockSize);
        const unsigned int preBatchBlocks = (unsigned int)std::ceil((float)(numPre * batchSize) / (float)blockSize);
        std::cout << "Mode:" << s_ModeNames[mode] << ", pre:" << numPre << ", num post:" << numPost << ", batch size:" << batchSize << ", block size:" << blockSize << std::endl;
    
        CHECK_CUDA_ERRORS(cudaSetDevice(0));

        //------------------------------------------------------------------------
        // Configure fixed-probability connector
        //------------------------------------------------------------------------
        // Create arrays to hold post-synaptic currents
        auto outCurrents = allocateHostDevice<float>(numPost * batchSize);
        std::fill_n(&outCurrents.first[0], numPost * batchSize, 0.0f);
        hostToDeviceCopy(outCurrents, numPost * batchSize);

        SparseMatrix sparseMatrix;
        HostDeviceArray<float> weights;
        {
            std::mt19937 gen;
            Timer<std::milli> t("Building sparse matrix:");

            buildFixedProbabilityConnector(numPre, numPost, connectionProbability, sparseMatrix, gen);
            std::cout << "Max row length:" << sparseMatrix.maxRowLength << std::endl;
        }

        // If weight isn't constant (in this context it doesn't really matter WHAT is in the memory)
        {
            Timer<std::milli> t("Initializing weights:");

            // Allocate, fill and upload weight array
            const unsigned int numIndices = numPre * sparseMatrix.maxRowLength;
            weights = allocateHostDevice<float>(numIndices);
            std::fill_n(&weights.first[0], numIndices, 1.0f);
            hostToDeviceCopy(weights, numIndices, true);
        }
        
        //------------------------------------------------------------------------
        // Configure poisson population
        //------------------------------------------------------------------------
        // Create arrays to hold poisson spike count
        auto poissonNumSpikes = allocateHostDevice<unsigned int>(batchSize);

        // Create arrays to hold poisson spikes
        auto poissonSpikes = allocateHostDevice<unsigned int>(numPre * batchSize);

        // Create arrays to hold poisson interspike intervals
        // **THINK** why not constant?
        auto poissonMeanISI = allocateHostDevice<float>(numPre * batchSize);
        std::fill_n(&poissonMeanISI.first[0], numPre * batchSize, 1000.0 / (poissonRate * dt));
        hostToDeviceCopy(poissonMeanISI, numPre * batchSize, true);

        // Create device random number generator states for poisson generators
        curandState *d_poissonState = nullptr;
        CHECK_CUDA_ERRORS(cudaMalloc(&d_poissonState, numPre * batchSize * sizeof(curandState)));
        {
            Timer<std::milli> t("Seed poisson:");
            // Initialise these seeds using kernel
            // **NOTE** first numPre sequences used by Poisson spike sources
            initRandomSeed <<<preBatchBlocks, blockSize >>>(numPre * batchSize, numPre * batchSize, d_poissonState);
            cudaDeviceSynchronize();
        }

        // Create device array for poisson generator time to spike
        float *d_poissonTimeToSpike = nullptr;
        CHECK_CUDA_ERRORS(cudaMalloc(&d_poissonTimeToSpike, numPre * batchSize * sizeof(float)));

        // Initialise time to spike using kernel
        {
            Timer<std::milli> t("Init poisson TTS:");
            initPoissonTimeToSpike <<<preBatchBlocks, blockSize>>>(numPre * batchSize, poissonMeanISI.second, d_poissonState,
                                                                   d_poissonTimeToSpike);
            cudaDeviceSynchronize();
        }
        const float connectionProbabilityReciprocal = 1.0f / std::log(1.0f - connectionProbability);
    
        // Create timing events
        cudaEvent_t kernelStartEvent;
        cudaEvent_t kernelEndEvent;
        double kernelTime = 0.0;
        CHECK_CUDA_ERRORS(cudaEventCreate(&kernelStartEvent));
        CHECK_CUDA_ERRORS(cudaEventCreate(&kernelEndEvent));

        {
            // Loop through time
            for (unsigned int t = 0; t < 5000; t++) {
                std::fill_n(&poissonNumSpikes.first[0], batchSize, 0);
                hostToDeviceCopy(poissonNumSpikes, batchSize);

                // Simulate poisson population
                {
                    const dim3 threads(blockSize, 1);
                    const dim3 grid(preBlocks, batchSize);
                    const unsigned int sharedBytes = blockSize * sizeof(unsigned int);
                    poisson <<<grid, threads, sharedBytes>>>(numPre, poissonMeanISI.second, d_poissonState,
                                                             d_poissonTimeToSpike, poissonNumSpikes.second, poissonSpikes.second);
                }

                // Copy spikes back to host
                deviceToHostCopy(poissonNumSpikes, 1);
            
                CHECK_CUDA_ERRORS(cudaEventRecord(kernelStartEvent));
                if(mode == ModeSparsePost) {
                    const unsigned int numPostSynapseBlocks = (unsigned int)std::ceil((float)sparseMatrix.maxRowLength / (float)blockSize);

                    const dim3 threads(blockSize, 1);
                    const dim3 grid(numPostSynapseBlocks, batchSize);
                    const unsigned int sharedBytes = blockSize * 2 * sizeof(unsigned int);
                    sparsePostIndividualWeight<<<grid, threads, sharedBytes>>>(sparseMatrix.rowLength.second, sparseMatrix.indices.second, 
                                                                               numPre, numPost, sparseMatrix.maxRowLength,
                                                                               poissonNumSpikes.second, poissonSpikes.second,
                                                                               weights.second, outCurrents.second);
                }

                CHECK_CUDA_ERRORS(cudaEventRecord(kernelEndEvent));
                CHECK_CUDA_ERRORS(cudaEventSynchronize(kernelEndEvent));

                float tmp;
                CHECK_CUDA_ERRORS(cudaEventElapsedTime(&tmp, kernelStartEvent, kernelEndEvent));
                kernelTime += tmp;
            }
        }

        std::cout << "Kernel time:" << kernelTime << " ms" << std::endl;

        deviceToHostCopy(outCurrents, numPost * batchSize);
        float meanCurrent = std::accumulate(&outCurrents.first[0], &outCurrents.first[numPost * batchSize], 0.0f) / (numPost * batchSize);
        std::cout << "Mean current:" << meanCurrent << ", estimated mean current:" << numPre * poissonRate * 5.0 * connectionProbability << std::endl;
    }
    catch(std::exception &ex)
    {
        std::cerr << ex.what() << std::endl;
        return EXIT_FAILURE;
    }

    return EXIT_SUCCESS;
}

